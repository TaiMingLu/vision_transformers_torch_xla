W&B online run started. URL: https://wandb.ai/ttl/tpu-vit/runs/560ymzue
TPU mode: Using num_workers=0 to avoid pickle issues, will use MpDeviceLoader for parallelism
Mixup is activated!
WARNING:timm.models._builder:No pretrained configuration specified for my_vit_b model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Forcing XLA synchronization after model.to(device)...
XLA mark_step() after model.to(device) completed
Forcing XLA synchronization before parameter counting...
XLA mark_step() completed
TPU spawned process: world_size = 64
Calculated total_batch_size = 16384
Number of training examples = 1281167
LR = 0.00400000
Batch size = 16384
Update frequent = 1
Number of training steps per epoch = 78
TPU multihost mode: XLA handles data distribution internally
About to create optimizer...
TPU mode: Using name-only parameter grouping to avoid XLA compilation
TPU mode: Collecting parameter names...
TPU mode: Found 152 trainable parameters
TPU mode: Grouping parameters by names...
Processing parameter 1/152: cls_token
Processing parameter 51/152: blocks.3.mlp.fc2.weight
Processing parameter 101/152: blocks.8.norm1.weight
Processing parameter 151/152: head.weight
TPU mode: Parameter names grouped successfully
TPU mode: Mapping names to tensors...
TPU mode: All 152 parameters mapped successfully
Parameter iteration completed! Processed 152 parameters.
TPU mode: Created 2 parameter groups, returning optimizer groups...
Parameter groups created successfully
Optimizer created successfully
TPU mode: Skipping loss scaler (XLA handles mixed precision)
TPU mode: About to set loss_scaler = None...
TPU mode: Loss scaler set to None
About to create Cosine LR scheduler...
Set warmup steps = 1560
LR scheduler created successfully
About to continue to weight decay scheduler...
About to check args.weight_decay_end...
Directly setting weight_decay_end to avoid freeze...
weight_decay_end set to: 0.05
About to call cosine_scheduler for weight decay...
Calling with: wd=0.05, wd_end=0.05, epochs=100, steps_per_epoch=78
Set warmup steps = 0
cosine_scheduler completed, about to calculate min/max...
Weight decay schedule created: 0.05 -> 0.05
About to create criterion...
Created SoftTargetCrossEntropy criterion
criterion = SoftTargetCrossEntropy()
TPU mode: Skipping warmup (caused shape errors), will compile on first iteration
About to call auto_load_model...
auto_load_model completed
About to define get_eval_model helper function...
get_eval_model function defined
About to set max_accuracy...
max_accuracy initialized
✅ Original train sampler preserved: <class 'torch.utils.data.distributed.DistributedSampler'>
🧪 DEBUG: MpDeviceLoader disabled for testing - using regular DataLoaders
Start training for 100 epochs
About to record start_time...
About to enter training loop...
Starting epoch 0 (delay since last epoch: 0.00s)...
Setting sampler epoch...
About to call original_train_sampler.set_epoch(0)...
✅ original_train_sampler.set_epoch(0) completed in 0.00s
Setting wandb steps...
About to call train_one_epoch...
🎯 train_one_epoch called for epoch 0
About to zero_grad optimizer...
About to start data loader loop...
About to call enumerate(metric_logger.log_every(...))...
TPU mode: Using direct DataLoader enumeration to avoid metric_logger overhead
TPU mode: About to call enumerate(device_loader)...
TPU mode: enumerate(device_loader) creation took 0.00s
📊 First enumerate() call took 11.55s
TPU mode: About to extract samples and targets from first batch...
TPU mode: First batch extraction took 0.00s
🚀 Starting data_iter_step 0 (DataLoader iteration took 0.000s)...
Epoch: [0] [0/78] eta: 0:01:18 loss: 7.0938 lr: 0.000000 time: 20.6808 data: 0.0001
🚀 Starting data_iter_step 1 (DataLoader iteration took 52.218s)...
🚀 Starting data_iter_step 2 (DataLoader iteration took 44.838s)...
🚀 Starting data_iter_step 3 (DataLoader iteration took 32.573s)...
🚀 Starting data_iter_step 4 (DataLoader iteration took 32.520s)...
🚀 Starting data_iter_step 5 (DataLoader iteration took 31.601s)...
🚀 Starting data_iter_step 6 (DataLoader iteration took 32.239s)...
🚀 Starting data_iter_step 7 (DataLoader iteration took 32.110s)...
🚀 Starting data_iter_step 8 (DataLoader iteration took 32.645s)...
🚀 Starting data_iter_step 9 (DataLoader iteration took 32.579s)...
🚀 Starting data_iter_step 10 (DataLoader iteration took 32.020s)...
Epoch: [0] [10/78] eta: 0:00:14 loss: 7.0625 lr: 0.000026 time: 0.2171 data: 32.0199
🚀 Starting data_iter_step 11 (DataLoader iteration took 33.123s)...
🚀 Starting data_iter_step 12 (DataLoader iteration took 31.998s)...
🚀 Starting data_iter_step 13 (DataLoader iteration took 32.889s)...
🚀 Starting data_iter_step 14 (DataLoader iteration took 31.930s)...
🚀 Starting data_iter_step 15 (DataLoader iteration took 31.358s)...
🚀 Starting data_iter_step 16 (DataLoader iteration took 31.457s)...
🚀 Starting data_iter_step 17 (DataLoader iteration took 31.353s)...
🚀 Starting data_iter_step 18 (DataLoader iteration took 31.950s)...
🚀 Starting data_iter_step 19 (DataLoader iteration took 31.224s)...
🚀 Starting data_iter_step 20 (DataLoader iteration took 31.685s)...
Epoch: [0] [20/78] eta: 0:00:13 loss: 7.0625 lr: 0.000051 time: 0.2319 data: 31.6851
🚀 Starting data_iter_step 21 (DataLoader iteration took 31.657s)...
🚀 Starting data_iter_step 22 (DataLoader iteration took 31.691s)...
🚀 Starting data_iter_step 23 (DataLoader iteration took 31.532s)...
🚀 Starting data_iter_step 24 (DataLoader iteration took 31.670s)...
🚀 Starting data_iter_step 25 (DataLoader iteration took 31.654s)...
🚀 Starting data_iter_step 26 (DataLoader iteration took 31.363s)...
🚀 Starting data_iter_step 27 (DataLoader iteration took 31.417s)...
🚀 Starting data_iter_step 28 (DataLoader iteration took 31.679s)...
🚀 Starting data_iter_step 29 (DataLoader iteration took 31.831s)...
🚀 Starting data_iter_step 30 (DataLoader iteration took 32.107s)...
Epoch: [0] [30/78] eta: 0:00:17 loss: 7.0312 lr: 0.000077 time: 0.3597 data: 32.1066
🚀 Starting data_iter_step 31 (DataLoader iteration took 32.039s)...
🚀 Starting data_iter_step 32 (DataLoader iteration took 31.667s)...
🚀 Starting data_iter_step 33 (DataLoader iteration took 32.328s)...
🚀 Starting data_iter_step 34 (DataLoader iteration took 32.570s)...
🚀 Starting data_iter_step 35 (DataLoader iteration took 31.873s)...
🚀 Starting data_iter_step 36 (DataLoader iteration took 32.639s)...
🚀 Starting data_iter_step 37 (DataLoader iteration took 32.151s)...
🚀 Starting data_iter_step 38 (DataLoader iteration took 32.233s)...
🚀 Starting data_iter_step 39 (DataLoader iteration took 32.358s)...
🚀 Starting data_iter_step 40 (DataLoader iteration took 33.013s)...
Epoch: [0] [40/78] eta: 0:00:08 loss: 6.9688 lr: 0.000103 time: 0.2322 data: 33.0133
🚀 Starting data_iter_step 41 (DataLoader iteration took 32.446s)...
🚀 Starting data_iter_step 42 (DataLoader iteration took 32.561s)...
🚀 Starting data_iter_step 43 (DataLoader iteration took 32.070s)...
