W&B online run started. URL: https://wandb.ai/ttl/tpu-vit/runs/exky4yw8
Mixup is activated!
WARNING:timm.models._builder:No pretrained configuration specified for my_vit_b model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Forcing XLA synchronization after model.to(device)...
XLA mark_step() after model.to(device) completed
Forcing XLA synchronization before parameter counting...
XLA mark_step() completed
TPU spawned process: world_size = 32
Calculated total_batch_size = 4096
Number of training examples = 1281167
LR = 0.00400000
Batch size = 4096
Update frequent = 1
Number of training steps per epoch = 312
TPU multihost mode: XLA handles data distribution internally
About to create optimizer...
TPU mode: About to call xm.mark_step() before parameter iteration...
TPU mode: xm.mark_step() completed
TPU mode: Using name-only parameter grouping to avoid XLA compilation
TPU mode: Collecting parameter names...
TPU mode: Found 152 trainable parameters
TPU mode: Grouping parameters by names...
Processing parameter 1/152: cls_token
Processing parameter 51/152: blocks.3.mlp.fc2.weight
Processing parameter 101/152: blocks.8.norm1.weight
Processing parameter 151/152: head.weight
TPU mode: Parameter names grouped successfully
TPU mode: Mapping names to tensors...
TPU mode: All 152 parameters mapped successfully
Parameter iteration completed! Processed 152 parameters.
TPU mode: Final XLA synchronization...
TPU mode: Final mark_step() completed
About to print param groups...
TPU mode: Skipping detailed param group printing to avoid XLA issues
Created 2 parameter groups
  - no_decay: 102 parameters
  - decay: 50 parameters
About to return parameter groups...
Parameter groups created successfully
Optimizer created successfully
TPU mode: Skipping loss scaler (XLA handles mixed precision)
TPU mode: About to set loss_scaler = None...
TPU mode: Loss scaler set to None
About to create Cosine LR scheduler...
Set warmup steps = 6240
LR scheduler created successfully
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
TPU mode: Skipping warmup (caused shape errors), will compile on first iteration
Start training for 100 epochs
TPU mode: Processing iteration 0, step 0, samples shape: torch.Size([128, 3, 224, 224])
TPU mode: Starting XLA step for iteration 0...
TPU mode: Current device = xla:0, device type = xla
TPU mode: samples.device = xla:0
TPU mode: targets.device = xla:0
TPU mode: model device = xla:0
TPU mode: Iteration 0 completed in 48.23s
TPU mode: Iteration 0, TPU memory: {'bytes_used': 1089426432, 'bytes_limit': 34088157184}
Epoch: [0]  [  0/312]  eta: 5:35:53  loss: 7.0938 (7.0938)  lr: 0.0000 (0.0000)  time: 64.5943  data: 10.1627
TPU mode: Starting XLA step for iteration 1...
TPU mode: Iteration 1 completed in 46.05s
TPU mode: Starting XLA step for iteration 2...
TPU mode: Iteration 2 completed in 0.62s
TPU mode: Starting XLA step for iteration 3...
TPU mode: Iteration 3 completed in 0.62s
TPU mode: Starting XLA step for iteration 4...
TPU mode: Iteration 4 completed in 0.60s
TPU mode: Starting XLA step for iteration 5...
TPU mode: Starting XLA step for iteration 6...
TPU mode: Starting XLA step for iteration 7...
TPU mode: Starting XLA step for iteration 8...
TPU mode: Starting XLA step for iteration 9...
TPU mode: Starting XLA step for iteration 10...
Epoch: [0]  [ 10/312]  eta: 2:28:59  loss: 7.0625 (7.0739)  lr: 0.0000 (0.0000)  time: 29.6011  data: 16.4535
TPU mode: Starting XLA step for iteration 11...
TPU mode: Starting XLA step for iteration 12...
TPU mode: Starting XLA step for iteration 13...
TPU mode: Starting XLA step for iteration 14...
TPU mode: Starting XLA step for iteration 15...
TPU mode: Starting XLA step for iteration 16...
TPU mode: Starting XLA step for iteration 17...
TPU mode: Starting XLA step for iteration 18...
TPU mode: Starting XLA step for iteration 19...
TPU mode: Starting XLA step for iteration 20...
Epoch: [0]  [ 20/312]  eta: 2:03:48  loss: 7.0625 (7.0729)  lr: 0.0000 (0.0000)  time: 23.4821  data: 17.6865
TPU mode: Starting XLA step for iteration 21...
TPU mode: Starting XLA step for iteration 22...
TPU mode: Starting XLA step for iteration 23...
TPU mode: Starting XLA step for iteration 24...
TPU mode: Starting XLA step for iteration 25...
TPU mode: Starting XLA step for iteration 26...
TPU mode: Starting XLA step for iteration 27...
TPU mode: Starting XLA step for iteration 28...
TPU mode: Starting XLA step for iteration 29...
TPU mode: Starting XLA step for iteration 30...
Epoch: [0]  [ 30/312]  eta: 1:52:45  loss: 7.0312 (7.0565)  lr: 0.0000 (0.0000)  time: 20.9036  data: 18.4822
TPU mode: Starting XLA step for iteration 31...
TPU mode: Starting XLA step for iteration 32...
TPU mode: Starting XLA step for iteration 33...
TPU mode: Starting XLA step for iteration 34...
TPU mode: Starting XLA step for iteration 35...
TPU mode: Starting XLA step for iteration 36...
TPU mode: Starting XLA step for iteration 37...
TPU mode: Starting XLA step for iteration 38...
TPU mode: Starting XLA step for iteration 39...
TPU mode: Starting XLA step for iteration 40...
Epoch: [0]  [ 40/312]  eta: 1:45:17  loss: 7.0312 (7.0595)  lr: 0.0000 (0.0000)  time: 20.8986  data: 18.7842
TPU mode: Starting XLA step for iteration 41...
TPU mode: Starting XLA step for iteration 42...
TPU mode: Starting XLA step for iteration 43...
TPU mode: Starting XLA step for iteration 44...
TPU mode: Starting XLA step for iteration 45...
TPU mode: Starting XLA step for iteration 46...
TPU mode: Starting XLA step for iteration 47...
TPU mode: Starting XLA step for iteration 48...
TPU mode: Starting XLA step for iteration 49...
TPU mode: Processing iteration 50, step 50, samples shape: torch.Size([128, 3, 224, 224])
TPU mode: Starting XLA step for iteration 50...
TPU mode: Iteration 50, TPU memory: {'bytes_used': 1278531072, 'bytes_limit': 34088157184}
Epoch: [0]  [ 50/312]  eta: 1:39:21  loss: 7.0625 (7.0564)  lr: 0.0000 (0.0000)  time: 20.8387  data: 18.8546
TPU mode: Starting XLA step for iteration 51...
TPU mode: Starting XLA step for iteration 52...
TPU mode: Starting XLA step for iteration 53...
TPU mode: Starting XLA step for iteration 54...
TPU mode: Starting XLA step for iteration 55...
TPU mode: Starting XLA step for iteration 56...
TPU mode: Starting XLA step for iteration 57...
TPU mode: Starting XLA step for iteration 58...
TPU mode: Starting XLA step for iteration 59...
TPU mode: Starting XLA step for iteration 60...
Epoch: [0]  [ 60/312]  eta: 1:34:16  loss: 7.0312 (7.0523)  lr: 0.0000 (0.0000)  time: 20.8457  data: 18.8069
TPU mode: Starting XLA step for iteration 61...
TPU mode: Starting XLA step for iteration 62...
