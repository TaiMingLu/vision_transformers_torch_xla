W&B online run started. URL: https://wandb.ai/ttl/tpu-vit/runs/u1p4c567
Mixup is activated!
WARNING:timm.models._builder:No pretrained configuration specified for my_vit_b model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Forcing XLA synchronization after model.to(device)...
XLA mark_step() after model.to(device) completed
Forcing XLA synchronization before parameter counting...
XLA mark_step() completed
TPU spawned process: world_size = 32
Calculated total_batch_size = 4096
Number of training examples = 1281167
LR = 0.00400000
Batch size = 4096
Update frequent = 1
Number of training steps per epoch = 312
TPU multihost mode: XLA handles data distribution internally
About to create optimizer...
TPU mode: Using name-only parameter grouping to avoid XLA compilation
TPU mode: Collecting parameter names...
TPU mode: Found 152 trainable parameters
TPU mode: Grouping parameters by names...
Processing parameter 1/152: cls_token
Processing parameter 51/152: blocks.3.mlp.fc2.weight
Processing parameter 101/152: blocks.8.norm1.weight
Processing parameter 151/152: head.weight
TPU mode: Parameter names grouped successfully
TPU mode: Mapping names to tensors...
TPU mode: All 152 parameters mapped successfully
Parameter iteration completed! Processed 152 parameters.
TPU mode: Created 2 parameter groups, returning optimizer groups...
Parameter groups created successfully
Optimizer created successfully
TPU mode: Skipping loss scaler (XLA handles mixed precision)
TPU mode: About to set loss_scaler = None...
TPU mode: Loss scaler set to None
About to create Cosine LR scheduler...
Set warmup steps = 6240
LR scheduler created successfully
About to continue to weight decay scheduler...
About to check args.weight_decay_end...
Directly setting weight_decay_end to avoid freeze...
weight_decay_end set to: 0.05
About to call cosine_scheduler for weight decay...
Calling with: wd=0.05, wd_end=0.05, epochs=100, steps_per_epoch=312
Set warmup steps = 0
cosine_scheduler completed, about to calculate min/max...
Weight decay schedule created: 0.05 -> 0.05
About to create criterion...
Created SoftTargetCrossEntropy criterion
criterion = SoftTargetCrossEntropy()
TPU mode: Skipping warmup (caused shape errors), will compile on first iteration
About to call auto_load_model...
auto_load_model completed
About to define get_eval_model helper function...
get_eval_model function defined
About to set max_accuracy...
max_accuracy initialized
Start training for 100 epochs
About to record start_time...
About to enter training loop...
Starting epoch 0...
Setting sampler epoch...
Setting wandb steps...
About to call train_one_epoch...
train_one_epoch started: epoch=0, tpu=True
About to zero_grad optimizer...
About to start data loader loop...
ğŸš€ Starting data_iter_step 0 (DataLoader iteration took 0.000s)...
Calculated step = 0, num_training_steps_per_epoch = 312
Global iteration it = 0
TPU mode: Processing iteration 0, step 0, samples shape: torch.Size([128, 3, 224, 224])
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 0...
TPU mode: Current device = xla:0, device type = xla
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
TPU mode: samples.device = xla:0
TPU mode: targets.device = xla:0
TPU mode: model device = xla:0
About to call model forward...
âœ… Model forward completed in 0.020s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.023s
About to run optimizer step...
âœ… Optimizer step completed in 26.560s
ğŸ”¥ Total XLA step time: 38.185s
TPU mode: Iteration 0 completed in 38.19s
ğŸ“ End of iteration 0 - about to continue loop...
TPU mode: Iteration 0, TPU memory: {'bytes_used': 1119007744, 'bytes_limit': 33550237696}
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 18.740s
âœ… Wandb logged in 0.000s
Epoch: [0]  [  0/312]  eta: 4:59:53  loss: 7.0938 (7.0938)  lr: 0.0000 (0.0000)  time: 57.6728  data: 0.7428
ğŸš€ Starting data_iter_step 1 (DataLoader iteration took 34.613s)...
Calculated step = 1, num_training_steps_per_epoch = 312
Global iteration it = 1
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 1...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.012s
About to call model forward...
âœ… Model forward completed in 0.014s, about to compute loss...
âœ… Loss computed in 0.000s: 7.09375, about to backward...
âœ… Backward completed in 0.016s
About to run optimizer step...
âœ… Optimizer step completed in 28.995s
ğŸ”¥ Total XLA step time: 29.156s
TPU mode: Iteration 1 completed in 29.21s
ğŸ“ End of iteration 1 - about to continue loop...
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 10.533s
âœ… Wandb logged in 0.000s
ğŸš€ Starting data_iter_step 2 (DataLoader iteration took 26.498s)...
Calculated step = 2, num_training_steps_per_epoch = 312
Global iteration it = 2
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 2...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.007s
About to call model forward...
âœ… Model forward completed in 0.014s, about to compute loss...
âœ… Loss computed in 0.001s: 7.15625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.183s
ğŸ”¥ Total XLA step time: 0.238s
TPU mode: Iteration 2 completed in 0.25s
ğŸ“ End of iteration 2 - about to continue loop...
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 0.213s
âœ… Wandb logged in 0.000s
ğŸš€ Starting data_iter_step 3 (DataLoader iteration took 15.955s)...
Calculated step = 3, num_training_steps_per_epoch = 312
Global iteration it = 3
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 3...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.008s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.09375, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.183s
ğŸ”¥ Total XLA step time: 0.240s
TPU mode: Iteration 3 completed in 0.25s
ğŸ“ End of iteration 3 - about to continue loop...
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 0.227s
âœ… Wandb logged in 0.000s
ğŸš€ Starting data_iter_step 4 (DataLoader iteration took 15.830s)...
Calculated step = 4, num_training_steps_per_epoch = 312
Global iteration it = 4
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 4...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.022s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 6.96875, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.183s
ğŸ”¥ Total XLA step time: 0.257s
TPU mode: Iteration 4 completed in 0.34s
ğŸ“ End of iteration 4 - about to continue loop...
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 0.161s
âœ… Wandb logged in 0.000s
ğŸš€ Starting data_iter_step 5 (DataLoader iteration took 15.679s)...
Calculated step = 5, num_training_steps_per_epoch = 312
Global iteration it = 5
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 5...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.033s
About to call model forward...
âœ… Model forward completed in 0.023s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0, about to backward...
âœ… Backward completed in 0.021s
About to run optimizer step...
âœ… Optimizer step completed in 0.187s
ğŸ”¥ Total XLA step time: 0.305s
TPU mode: Iteration 5 completed in 0.47s
ğŸ“ End of iteration 5 - about to continue loop...
âœ… Wandb logged in 0.236s
ğŸš€ Starting data_iter_step 6 (DataLoader iteration took 15.831s)...
Calculated step = 6, num_training_steps_per_epoch = 312
Global iteration it = 6
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 6...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.006s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0625, about to backward...
âœ… Backward completed in 0.011s
About to run optimizer step...
âœ… Optimizer step completed in 0.217s
ğŸ”¥ Total XLA step time: 0.269s
TPU mode: Iteration 6 completed in 0.28s
ğŸ“ End of iteration 6 - about to continue loop...
âœ… Wandb logged in 0.091s
ğŸš€ Starting data_iter_step 7 (DataLoader iteration took 15.407s)...
Calculated step = 7, num_training_steps_per_epoch = 312
Global iteration it = 7
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 7...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.030s
About to call model forward...
âœ… Model forward completed in 0.016s, about to compute loss...
âœ… Loss computed in 0.000s: 7.125, about to backward...
âœ… Backward completed in 0.013s
About to run optimizer step...
âœ… Optimizer step completed in 0.189s
ğŸ”¥ Total XLA step time: 0.276s
TPU mode: Iteration 7 completed in 0.39s
ğŸ“ End of iteration 7 - about to continue loop...
âœ… Wandb logged in 0.321s
ğŸš€ Starting data_iter_step 8 (DataLoader iteration took 15.892s)...
Calculated step = 8, num_training_steps_per_epoch = 312
Global iteration it = 8
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 8...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.040s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.000s: 7.09375, about to backward...
âœ… Backward completed in 0.016s
About to run optimizer step...
âœ… Optimizer step completed in 0.184s
ğŸ”¥ Total XLA step time: 0.282s
TPU mode: Iteration 8 completed in 0.40s
ğŸ“ End of iteration 8 - about to continue loop...
âœ… Wandb logged in 0.086s
ğŸš€ Starting data_iter_step 9 (DataLoader iteration took 15.590s)...
Calculated step = 9, num_training_steps_per_epoch = 312
Global iteration it = 9
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 9...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.027s
About to call model forward...
âœ… Model forward completed in 0.020s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0625, about to backward...
âœ… Backward completed in 0.014s
About to run optimizer step...
âœ… Optimizer step completed in 0.189s
ğŸ”¥ Total XLA step time: 0.295s
TPU mode: Iteration 9 completed in 0.44s
ğŸ“ End of iteration 9 - about to continue loop...
âœ… Wandb logged in 0.083s
ğŸš€ Starting data_iter_step 10 (DataLoader iteration took 11.270s)...
Calculated step = 10, num_training_steps_per_epoch = 312
Global iteration it = 10
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 10...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.184s
ğŸ”¥ Total XLA step time: 0.232s
TPU mode: Iteration 10 completed in 0.23s
ğŸ“ End of iteration 10 - about to continue loop...
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 0.932s
âœ… Wandb logged in 0.000s
Epoch: [0]  [ 10/312]  eta: 1:56:33  loss: 7.0938 (7.0729)  lr: 0.0000 (0.0000)  time: 23.1563  data: 13.8731
ğŸš€ Starting data_iter_step 11 (DataLoader iteration took 16.862s)...
Calculated step = 11, num_training_steps_per_epoch = 312
Global iteration it = 11
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 11...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.188s
ğŸ”¥ Total XLA step time: 0.243s
TPU mode: Iteration 11 completed in 0.25s
ğŸ“ End of iteration 11 - about to continue loop...
âœ… Wandb logged in 0.188s
ğŸš€ Starting data_iter_step 12 (DataLoader iteration took 15.776s)...
Calculated step = 12, num_training_steps_per_epoch = 312
Global iteration it = 12
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 12...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.012s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.001s: 7.09375, about to backward...
âœ… Backward completed in 0.023s
About to run optimizer step...
âœ… Optimizer step completed in 0.213s
ğŸ”¥ Total XLA step time: 0.289s
TPU mode: Iteration 12 completed in 0.39s
ğŸ“ End of iteration 12 - about to continue loop...
âœ… Wandb logged in 0.098s
ğŸš€ Starting data_iter_step 13 (DataLoader iteration took 15.622s)...
Calculated step = 13, num_training_steps_per_epoch = 312
Global iteration it = 13
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 13...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.013s
About to call model forward...
âœ… Model forward completed in 0.016s, about to compute loss...
âœ… Loss computed in 0.000s: 7.09375, about to backward...
âœ… Backward completed in 0.015s
About to run optimizer step...
âœ… Optimizer step completed in 0.184s
ğŸ”¥ Total XLA step time: 0.259s
TPU mode: Iteration 13 completed in 0.35s
ğŸ“ End of iteration 13 - about to continue loop...
âœ… Wandb logged in 0.081s
ğŸš€ Starting data_iter_step 14 (DataLoader iteration took 15.844s)...
Calculated step = 14, num_training_steps_per_epoch = 312
Global iteration it = 14
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 14...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.034s
About to call model forward...
âœ… Model forward completed in 0.017s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.022s
About to run optimizer step...
âœ… Optimizer step completed in 0.218s
ğŸ”¥ Total XLA step time: 0.327s
TPU mode: Iteration 14 completed in 0.45s
ğŸ“ End of iteration 14 - about to continue loop...
âœ… Wandb logged in 0.081s
ğŸš€ Starting data_iter_step 15 (DataLoader iteration took 15.479s)...
Calculated step = 15, num_training_steps_per_epoch = 312
Global iteration it = 15
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 15...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.032s
About to call model forward...
âœ… Model forward completed in 0.020s, about to compute loss...
âœ… Loss computed in 0.000s: 7.09375, about to backward...
âœ… Backward completed in 0.015s
About to run optimizer step...
âœ… Optimizer step completed in 0.187s
ğŸ”¥ Total XLA step time: 0.284s
TPU mode: Iteration 15 completed in 0.45s
ğŸ“ End of iteration 15 - about to continue loop...
âœ… Wandb logged in 0.087s
ğŸš€ Starting data_iter_step 16 (DataLoader iteration took 15.575s)...
Calculated step = 16, num_training_steps_per_epoch = 312
Global iteration it = 16
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 16...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.035s
About to call model forward...
âœ… Model forward completed in 0.016s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.187s
ğŸ”¥ Total XLA step time: 0.280s
TPU mode: Iteration 16 completed in 0.43s
ğŸ“ End of iteration 16 - about to continue loop...
âœ… Wandb logged in 0.084s
ğŸš€ Starting data_iter_step 17 (DataLoader iteration took 15.610s)...
Calculated step = 17, num_training_steps_per_epoch = 312
Global iteration it = 17
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 17...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.030s
About to call model forward...
âœ… Model forward completed in 0.016s, about to compute loss...
âœ… Loss computed in 0.001s: 6.96875, about to backward...
âœ… Backward completed in 0.022s
About to run optimizer step...
âœ… Optimizer step completed in 0.242s
ğŸ”¥ Total XLA step time: 0.341s
TPU mode: Iteration 17 completed in 0.45s
ğŸ“ End of iteration 17 - about to continue loop...
âœ… Wandb logged in 0.086s
ğŸš€ Starting data_iter_step 18 (DataLoader iteration took 15.272s)...
Calculated step = 18, num_training_steps_per_epoch = 312
Global iteration it = 18
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 18...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.027s
About to call model forward...
âœ… Model forward completed in 0.017s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.204s
ğŸ”¥ Total XLA step time: 0.289s
TPU mode: Iteration 18 completed in 0.40s
ğŸ“ End of iteration 18 - about to continue loop...
âœ… Wandb logged in 0.083s
ğŸš€ Starting data_iter_step 19 (DataLoader iteration took 15.218s)...
Calculated step = 19, num_training_steps_per_epoch = 312
Global iteration it = 19
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 19...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.023s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.013s
About to run optimizer step...
âœ… Optimizer step completed in 0.202s
ğŸ”¥ Total XLA step time: 0.282s
TPU mode: Iteration 19 completed in 0.40s
ğŸ“ End of iteration 19 - about to continue loop...
âœ… Wandb logged in 0.078s
ğŸš€ Starting data_iter_step 20 (DataLoader iteration took 12.005s)...
Calculated step = 20, num_training_steps_per_epoch = 312
Global iteration it = 20
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 20...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.185s
ğŸ”¥ Total XLA step time: 0.234s
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 0.080s
âœ… Wandb logged in 0.000s
Epoch: [0]  [ 20/312]  eta: 1:35:14  loss: 7.0938 (7.0670)  lr: 0.0000 (0.0000)  time: 17.6642  data: 15.1661
ğŸš€ Starting data_iter_step 21 (DataLoader iteration took 27.981s)...
Calculated step = 21, num_training_steps_per_epoch = 312
Global iteration it = 21
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 21...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.036s
About to call model forward...
âœ… Model forward completed in 0.014s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.014s
About to run optimizer step...
âœ… Optimizer step completed in 0.182s
ğŸ”¥ Total XLA step time: 0.272s
âœ… Wandb logged in 0.331s
ğŸš€ Starting data_iter_step 22 (DataLoader iteration took 43.895s)...
Calculated step = 22, num_training_steps_per_epoch = 312
Global iteration it = 22
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 22...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.183s
ğŸ”¥ Total XLA step time: 0.230s
âœ… Wandb logged in 0.693s
ğŸš€ Starting data_iter_step 23 (DataLoader iteration took 58.694s)...
Calculated step = 23, num_training_steps_per_epoch = 312
Global iteration it = 23
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 23...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.004s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.000s: 7.09375, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.269s
ğŸ”¥ Total XLA step time: 0.321s
âœ… Wandb logged in 1.792s
ğŸš€ Starting data_iter_step 24 (DataLoader iteration took 75.967s)...
Calculated step = 24, num_training_steps_per_epoch = 312
Global iteration it = 24
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 24...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.026s
About to call model forward...
âœ… Model forward completed in 0.034s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.026s
About to run optimizer step...
âœ… Optimizer step completed in 0.243s
ğŸ”¥ Total XLA step time: 0.366s
âœ… Wandb logged in 0.751s
ğŸš€ Starting data_iter_step 25 (DataLoader iteration took 92.302s)...
Calculated step = 25, num_training_steps_per_epoch = 312
Global iteration it = 25
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 25...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.049s
About to call model forward...
âœ… Model forward completed in 0.016s, about to compute loss...
âœ… Loss computed in 0.003s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.212s
ğŸ”¥ Total XLA step time: 0.329s
âœ… Wandb logged in 0.147s
ğŸš€ Starting data_iter_step 26 (DataLoader iteration took 107.892s)...
Calculated step = 26, num_training_steps_per_epoch = 312
Global iteration it = 26
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 26...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.028s
About to call model forward...
âœ… Model forward completed in 0.020s, about to compute loss...
âœ… Loss computed in 0.000s: 6.96875, about to backward...
âœ… Backward completed in 0.019s
About to run optimizer step...
âœ… Optimizer step completed in 0.186s
ğŸ”¥ Total XLA step time: 0.288s
âœ… Wandb logged in 0.444s
ğŸš€ Starting data_iter_step 27 (DataLoader iteration took 123.886s)...
Calculated step = 27, num_training_steps_per_epoch = 312
Global iteration it = 27
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 27...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.028s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.016s
About to run optimizer step...
âœ… Optimizer step completed in 0.185s
ğŸ”¥ Total XLA step time: 0.271s
âœ… Wandb logged in 0.320s
ğŸš€ Starting data_iter_step 28 (DataLoader iteration took 139.861s)...
Calculated step = 28, num_training_steps_per_epoch = 312
Global iteration it = 28
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 28...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.036s
About to call model forward...
âœ… Model forward completed in 0.015s, about to compute loss...
âœ… Loss computed in 0.001s: 6.96875, about to backward...
âœ… Backward completed in 0.016s
About to run optimizer step...
âœ… Optimizer step completed in 0.207s
ğŸ”¥ Total XLA step time: 0.297s
âœ… Wandb logged in 0.317s
ğŸš€ Starting data_iter_step 29 (DataLoader iteration took 155.979s)...
Calculated step = 29, num_training_steps_per_epoch = 312
Global iteration it = 29
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 29...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.029s
About to call model forward...
âœ… Model forward completed in 0.024s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.011s
About to run optimizer step...
âœ… Optimizer step completed in 0.186s
ğŸ”¥ Total XLA step time: 0.276s
âœ… Wandb logged in 0.087s
ğŸš€ Starting data_iter_step 30 (DataLoader iteration took 164.232s)...
Calculated step = 30, num_training_steps_per_epoch = 312
Global iteration it = 30
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 30...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.000s: 7.03125, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.183s
ğŸ”¥ Total XLA step time: 0.231s
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 3.244s
âœ… Wandb logged in 0.000s
Epoch: [0]  [ 30/312]  eta: 1:25:51  loss: 7.0312 (7.0625)  lr: 0.0000 (0.0000)  time: 15.5813  data: 14.7456
ğŸš€ Starting data_iter_step 31 (DataLoader iteration took 183.242s)...
Calculated step = 31, num_training_steps_per_epoch = 312
Global iteration it = 31
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 31...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.184s
ğŸ”¥ Total XLA step time: 0.237s
âœ… Wandb logged in 0.476s
ğŸš€ Starting data_iter_step 32 (DataLoader iteration took 198.817s)...
Calculated step = 32, num_training_steps_per_epoch = 312
Global iteration it = 32
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 32...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.038s
About to call model forward...
âœ… Model forward completed in 0.025s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.025s
About to run optimizer step...
âœ… Optimizer step completed in 0.256s
ğŸ”¥ Total XLA step time: 0.370s
âœ… Wandb logged in 0.677s
ğŸš€ Starting data_iter_step 33 (DataLoader iteration took 214.970s)...
Calculated step = 33, num_training_steps_per_epoch = 312
Global iteration it = 33
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 33...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.027s
About to call model forward...
âœ… Model forward completed in 0.014s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.015s
About to run optimizer step...
âœ… Optimizer step completed in 0.191s
ğŸ”¥ Total XLA step time: 0.276s
âœ… Wandb logged in 0.353s
ğŸš€ Starting data_iter_step 34 (DataLoader iteration took 231.019s)...
Calculated step = 34, num_training_steps_per_epoch = 312
Global iteration it = 34
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 34...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.029s
About to call model forward...
âœ… Model forward completed in 0.015s, about to compute loss...
âœ… Loss computed in 0.000s: 7.03125, about to backward...
âœ… Backward completed in 0.014s
About to run optimizer step...
âœ… Optimizer step completed in 0.195s
ğŸ”¥ Total XLA step time: 0.285s
âœ… Wandb logged in 0.574s
ğŸš€ Starting data_iter_step 35 (DataLoader iteration took 247.402s)...
Calculated step = 35, num_training_steps_per_epoch = 312
Global iteration it = 35
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 35...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.034s
About to call model forward...
âœ… Model forward completed in 0.014s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.025s
About to run optimizer step...
âœ… Optimizer step completed in 0.204s
ğŸ”¥ Total XLA step time: 0.308s
âœ… Wandb logged in 0.082s
ğŸš€ Starting data_iter_step 36 (DataLoader iteration took 263.089s)...
Calculated step = 36, num_training_steps_per_epoch = 312
Global iteration it = 36
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 36...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.035s
About to call model forward...
âœ… Model forward completed in 0.019s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0, about to backward...
âœ… Backward completed in 0.014s
About to run optimizer step...
âœ… Optimizer step completed in 0.192s
ğŸ”¥ Total XLA step time: 0.285s
âœ… Wandb logged in 0.082s
ğŸš€ Starting data_iter_step 37 (DataLoader iteration took 276.729s)...
Calculated step = 37, num_training_steps_per_epoch = 312
Global iteration it = 37
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 37...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.002s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0, about to backward...
âœ… Backward completed in 0.018s
About to run optimizer step...
âœ… Optimizer step completed in 0.281s
ğŸ”¥ Total XLA step time: 0.345s
âœ… Wandb logged in 2.020s
ğŸš€ Starting data_iter_step 38 (DataLoader iteration took 294.351s)...
Calculated step = 38, num_training_steps_per_epoch = 312
Global iteration it = 38
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 38...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.031s
About to call model forward...
âœ… Model forward completed in 0.017s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.213s
ğŸ”¥ Total XLA step time: 0.304s
âœ… Wandb logged in 0.183s
ğŸš€ Starting data_iter_step 39 (DataLoader iteration took 310.407s)...
Calculated step = 39, num_training_steps_per_epoch = 312
Global iteration it = 39
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 39...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.034s
About to call model forward...
âœ… Model forward completed in 0.019s, about to compute loss...
âœ… Loss computed in 0.000s: 7.03125, about to backward...
âœ… Backward completed in 0.013s
About to run optimizer step...
âœ… Optimizer step completed in 0.205s
ğŸ”¥ Total XLA step time: 0.299s
âœ… Wandb logged in 0.080s
ğŸš€ Starting data_iter_step 40 (DataLoader iteration took 321.534s)...
Calculated step = 40, num_training_steps_per_epoch = 312
Global iteration it = 40
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 40...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.03125, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.185s
ğŸ”¥ Total XLA step time: 0.233s
ğŸ”§ Starting metric updates...
âœ… Metric logger updated in 0.080s
âœ… Wandb logged in 0.000s
Epoch: [0]  [ 40/312]  eta: 1:19:39  loss: 7.0312 (7.0590)  lr: 0.0000 (0.0000)  time: 15.4764  data: 14.4547
ğŸš€ Starting data_iter_step 41 (DataLoader iteration took 337.746s)...
Calculated step = 41, num_training_steps_per_epoch = 312
Global iteration it = 41
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 41...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.004s
About to call model forward...
âœ… Model forward completed in 0.013s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.184s
ğŸ”¥ Total XLA step time: 0.238s
âœ… Wandb logged in 0.293s
ğŸš€ Starting data_iter_step 42 (DataLoader iteration took 353.465s)...
Calculated step = 42, num_training_steps_per_epoch = 312
Global iteration it = 42
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 42...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.002s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.186s
ğŸ”¥ Total XLA step time: 0.235s
âœ… Wandb logged in 0.580s
ğŸš€ Starting data_iter_step 43 (DataLoader iteration took 369.026s)...
Calculated step = 43, num_training_steps_per_epoch = 312
Global iteration it = 43
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 43...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.001s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.001s: 7.0, about to backward...
âœ… Backward completed in 0.011s
About to run optimizer step...
âœ… Optimizer step completed in 0.183s
ğŸ”¥ Total XLA step time: 0.232s
âœ… Wandb logged in 0.953s
ğŸš€ Starting data_iter_step 44 (DataLoader iteration took 383.973s)...
Calculated step = 44, num_training_steps_per_epoch = 312
Global iteration it = 44
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 44...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.013s
About to call model forward...
âœ… Model forward completed in 0.012s, about to compute loss...
âœ… Loss computed in 0.000s: 7.09375, about to backward...
âœ… Backward completed in 0.011s
About to run optimizer step...
âœ… Optimizer step completed in 0.192s
ğŸ”¥ Total XLA step time: 0.259s
âœ… Wandb logged in 1.799s
ğŸš€ Starting data_iter_step 45 (DataLoader iteration took 401.472s)...
Calculated step = 45, num_training_steps_per_epoch = 312
Global iteration it = 45
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 45...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.039s
About to call model forward...
âœ… Model forward completed in 0.017s, about to compute loss...
âœ… Loss computed in 0.001s: 7.15625, about to backward...
âœ… Backward completed in 0.021s
About to run optimizer step...
âœ… Optimizer step completed in 0.191s
ğŸ”¥ Total XLA step time: 0.301s
âœ… Wandb logged in 0.265s
ğŸš€ Starting data_iter_step 46 (DataLoader iteration took 416.964s)...
Calculated step = 46, num_training_steps_per_epoch = 312
Global iteration it = 46
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 46...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.020s
About to call model forward...
âœ… Model forward completed in 0.018s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.184s
ğŸ”¥ Total XLA step time: 0.263s
âœ… Wandb logged in 0.725s
ğŸš€ Starting data_iter_step 47 (DataLoader iteration took 431.339s)...
Calculated step = 47, num_training_steps_per_epoch = 312
Global iteration it = 47
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 47...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.036s
About to call model forward...
âœ… Model forward completed in 0.019s, about to compute loss...
âœ… Loss computed in 0.000s: 7.0625, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.195s
ğŸ”¥ Total XLA step time: 0.290s
âœ… Wandb logged in 1.926s
ğŸš€ Starting data_iter_step 48 (DataLoader iteration took 448.554s)...
Calculated step = 48, num_training_steps_per_epoch = 312
Global iteration it = 48
About to update LR/WD schedules...
âœ… LR/WD schedule update completed in 0.000s
About to enter forward/backward section, use_amp=False, tpu=True...
Taking TPU path...
TPU mode: Starting XLA step for iteration 48...
About to apply mixup if present...
About to enter torch_xla.step() context...
Inside torch_xla.step(), moving data to device...
âœ… Data moved to device in 0.049s
About to call model forward...
âœ… Model forward completed in 0.016s, about to compute loss...
âœ… Loss computed in 0.000s: 7.03125, about to backward...
âœ… Backward completed in 0.012s
About to run optimizer step...
âœ… Optimizer step completed in 0.187s
ğŸ”¥ Total XLA step time: 0.298s
âœ… Wandb logged in 1.017s
ğŸš€ Starting data_iter_step 49 (DataLoader iteration took 465.287s)...
Calculated step = 49, num_training_steps_per_epoch = 312
