W&B online run started. URL: https://wandb.ai/ttl/tpu-vit/runs/iljacm7h
Mixup is activated!
WARNING:timm.models._builder:No pretrained configuration specified for my_vit_b model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Forcing XLA synchronization after model.to(device)...
XLA mark_step() after model.to(device) completed
Using EMA with decay = 0.99990000
Forcing XLA synchronization before parameter counting...
XLA mark_step() completed
TPU spawned process: world_size = 32
Calculated total_batch_size = 2048
Number of training examples = 1281167
LR = 0.00400000
Batch size = 2048
Update frequent = 1
Number of training steps per epoch = 625
TPU multihost mode: XLA handles data distribution internally
About to create optimizer...
TPU mode: About to call xm.mark_step() before parameter iteration...
TPU mode: xm.mark_step() completed
About to iterate through named_parameters...
Processing parameter 10: blocks.0.attn.proj.bias
Processing parameter 20: blocks.1.attn.qkv.bias
Processing parameter 30: blocks.2.norm1.bias
Processing parameter 40: blocks.2.mlp.fc2.bias
Processing parameter 50: blocks.3.mlp.fc1.bias
Processing parameter 50: blocks.3.mlp.fc1.bias
Parameter blocks.3.mlp.fc1.bias added successfully (count: 50)
Processing parameter 60: blocks.4.norm2.bias
Processing parameter 70: blocks.5.attn.proj.bias
Processing parameter 80: blocks.6.attn.qkv.bias
Processing parameter 90: blocks.7.norm1.bias
Processing parameter 100: blocks.7.mlp.fc2.bias
Processing parameter 100: blocks.7.mlp.fc2.bias
Parameter blocks.7.mlp.fc2.bias added successfully (count: 100)
Processing parameter 110: blocks.8.mlp.fc1.bias
Processing parameter 120: blocks.9.norm2.bias
Processing parameter 130: blocks.10.attn.proj.bias
Processing parameter 140: blocks.11.attn.qkv.bias
Processing parameter 150: fc_norm.bias
Processing parameter 150: fc_norm.bias
Parameter fc_norm.bias added successfully (count: 150)
Parameter iteration completed! Processed 152 parameters.
TPU mode: Final XLA synchronization...
TPU mode: Final mark_step() completed
About to print param groups...
TPU mode: Skipping detailed param group printing to avoid XLA issues
Created 2 parameter groups
  - no_decay: 102 parameters
  - decay: 50 parameters
About to return parameter groups...
Parameter groups created successfully
Optimizer created successfully
Using device type: xla
About to create loss scaler...
Loss scaler created successfully
About to create Cosine LR scheduler...
Set warmup steps = 12500
LR scheduler created successfully
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Start training for 100 epochs
Epoch: [0]  [  0/625]  eta: 10:24:20  loss: 7.0312 (7.0312)  lr: 0.0000 (0.0000)  time: 59.9368  data: 0.5424
