W&B online run started. URL: https://wandb.ai/ttl/tpu-vit/runs/py3a21mr
Mixup is activated!
WARNING:timm.models._builder:No pretrained configuration specified for my_vit_b model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Forcing XLA synchronization after model.to(device)...
XLA mark_step() after model.to(device) completed
Forcing XLA synchronization before parameter counting...
XLA mark_step() completed
TPU spawned process: world_size = 32
Calculated total_batch_size = 4096
Number of training examples = 1281167
LR = 0.00400000
Batch size = 4096
Update frequent = 1
Number of training steps per epoch = 312
TPU multihost mode: XLA handles data distribution internally
About to create optimizer...
TPU mode: Using name-only parameter grouping to avoid XLA compilation
TPU mode: Collecting parameter names...
TPU mode: Found 152 trainable parameters
TPU mode: Grouping parameters by names...
Processing parameter 1/152: cls_token
Processing parameter 51/152: blocks.3.mlp.fc2.weight
Processing parameter 101/152: blocks.8.norm1.weight
Processing parameter 151/152: head.weight
TPU mode: Parameter names grouped successfully
TPU mode: Mapping names to tensors...
TPU mode: All 152 parameters mapped successfully
Parameter iteration completed! Processed 152 parameters.
TPU mode: Created 2 parameter groups, returning optimizer groups...
Parameter groups created successfully
Optimizer created successfully
TPU mode: Skipping loss scaler (XLA handles mixed precision)
TPU mode: About to set loss_scaler = None...
TPU mode: Loss scaler set to None
About to create Cosine LR scheduler...
Set warmup steps = 6240
LR scheduler created successfully
TPU mode: Checking for pending XLA operations after LR scheduler...
TPU mode: Current device status: xla:0
About to check args.weight_decay_end...
Setting args.weight_decay_end...
args.weight_decay_end set successfully
About to call cosine_scheduler for weight decay...
Set warmup steps = 0
cosine_scheduler completed, about to calculate min/max...
Weight decay schedule created: 0.05 -> 0.05
criterion = SoftTargetCrossEntropy()
TPU mode: Skipping warmup (caused shape errors), will compile on first iteration
Start training for 100 epochs
TPU mode: Processing iteration 0, step 0, samples shape: torch.Size([128, 3, 224, 224])
TPU mode: Starting XLA step for iteration 0...
TPU mode: Current device = xla:0, device type = xla
TPU mode: samples.device = xla:0
TPU mode: targets.device = xla:0
TPU mode: model device = xla:0
TPU mode: Iteration 0 completed in 48.50s
TPU mode: Iteration 0, TPU memory: {'bytes_used': 1089426432, 'bytes_limit': 34088157184}
Epoch: [0]  [  0/312]  eta: 5:40:09  loss: 7.0625 (7.0625)  lr: 0.0000 (0.0000)  time: 65.4155  data: 11.7957
TPU mode: Starting XLA step for iteration 1...
